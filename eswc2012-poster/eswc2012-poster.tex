\documentclass[runningheads,a4paper,11pt]{llncs}
\usepackage{fullpage}

\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfig}

% proper encoding
\usepackage[T1]{fontenc}
% use Times
\usepackage{mathptmx}

% autoref command
\usepackage[pdftex,urlcolor=black,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
\def\figureautorefname{Fig.}
\def\subfigureautorefname{Fig.}

% proper typography
\usepackage[protrusion,expansion,kerning,spacing,tracking]{microtype}

% URLs
\usepackage{url}

% todo macro
\usepackage{color}
\newcommand{\todo}[1]{\noindent\textcolor{red}{{\bf \{TODO} #1{\bf \}}}}

% listings and Verbatim environment
\usepackage{fancyvrb}
\usepackage{relsize}
\RecustomVerbatimCommand{\Verb}{Verb}{fontsize=\fontsize{9pt}{11pt}}
\RecustomVerbatimEnvironment{Verbatim}{Verbatim}{fontsize=\fontsize{9pt}{12pt}}
\usepackage{listings}
\lstset{frame=lines,captionpos=b,numberbychapter=false,escapechar=§,
        aboveskip=0em,belowskip=0em,abovecaptionskip=.3em,belowcaptionskip=0em,
        basicstyle=\ttfamily\fontsize{8.5pt}{9.5pt}\selectfont}

% linewrap symbol
\definecolor{grey}{RGB}{160,160,160}
\newcommand{\linewrap}{\raisebox{-.6ex}{\textcolor{grey}{$\hookleftarrow$}}}

% keywords command
\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\begin{document}

\mainmatter

\title{Ranking Criteria for Media Items Illustrating Events\\ Stemming from Multiple Social Networks}

% use Courier from this point onward (used CM for author e-mails), and smaller in-text URIs
\renewcommand{\ttdefault}{pcr}
\renewcommand\UrlFont{\smaller\tt}

\author{Thomas Steiner\inst{1} \and Ruben Verborgh\inst{2} \and Rik Van de Walle\inst{2} \and Joaquim Gabarro\inst{1}}

\institute{Universitat Politècnica de Catalunya -- Department LSI\\
08034 Barcelona, Spain\\
\email{\{tsteiner, gabarro\}@lsi.upc.edu}
\and Ghent University -- IBBT, ELIS -- Multimedia Lab\\Gaston Crommenlaan 8 bus 201, B-9050 Ledeberg-Ghent, Belgium\\
\email{\{ruben.verborgh, rik.vandewalle\}@ugent.be}
}

\authorrunning{Ranking Criteria for Media Items Illustrating Events}
% (feature abused for this document to repeat the title also on left hand pages)
% a short form should be given in case it is too long for the running head
\titlerunning{Ranking Criteria for Media Items Illustrating Events}

\maketitle

%%%%%%%%% ABSTRACT
\begin{abstract}
Mobile devices such as smartphones or digital cameras together with social networks
enable people to create, share, and consume enormous amounts of media items
like videos or images, both \textit{en route} or at home.
Such mobile devices---by pure definition---accompany their owners almost wherever they may go.
In consequence, mobile devices are omnipresent at all sorts of events
like keynote speeches at conferences, music concerts in stadiums,
or even natural catastrophes affecting whole areas or countries.
At such events---given a~stable network connection---media items are published
on social networks both as the event happens and afterwards.
Media items stemming from multiple social networks can serve to create authentic media galleries
that illustrate events from the view of event attendants and
that convey at least part of the atmosphere to those who did not attend the event.
In this paper, we present and discuss several ranking criteria that can help
triage and prune the potentially huge amount of available media items for a~given event.
A key feature for this task is the semantic enrichment of media items and the related metadata.
Besides high- and low-level \emph{visual} ranking criteria
such as contained objects or pixel resolution---and,
in consequence, leveraging the additional information coming from social networks---we introduce
\emph{textual} ranking criteria from associated microposts that accompany media items and
\emph{social} ranking criteria from social networking effects such as shares, mentions,
number of views, expressions of likes and dislikes, user diversity, etc.
Finally, we discuss media-specific \emph{aesthetic} ranking criteria such as the
variety of the included media items and the balance of video \emph{vs.} image media items.
\end{abstract}

\section{Motivational Event Scenarios}
In this Section, we discuss common event scenarios that serve to motivate the need
for ranking criteria for media items stemming from multiple social networks.
We assume (and are currently working on) a~set of functioning media item extractors
for multiple social networks that, given a~set of event-related search terms,
extract raw binary media items together with their accompanying metadata
like microposts, tags, descriptions, etc. from social networks like
Twitter, Facebook, Google+, Instagram, MySpace, YouTube, Flickr, etc.
In consequence, for the event scenario discussed below,
we take a~set of related media items like images or videos for granted.

Events like music concerts, sports matches, or keynote speeches
are typically very well covered social media wise.
The given contexts of the known artists, sports teams, or speakers
allow for leveraging knowledge from the
Linked Open Data (LOD) cloud\footnote{Linked Open Data cloud: \url{http://lod-cloud.net/}}.
This can be data about faces, names, or related concepts,
which, given semantic enrichment of the metadata through, e.g.,
named entity disambiguation, can serve to prune the set of media items
through face detection and recognition.
More concretely, a~video of the former German President \emph{Christian Wulff}
retrieved from a~social network through a~keyword search for \emph{``christian wulff''},
can be considered relevant for the---at time of writing---recent
event of his resignation speech\footnote{Christian Wulff's resignation speech:
\url{http://www.youtube.com/watch?v=PWJxM0d0NNQ}},
if (i), in the accompanying micropost the named entity represented by the DBpedia URI
\url{http://dbpedia.org/resource/Resignation_speech} is detected,
and if (ii), his face is recognized in the video.
In the given example, this video might outrank a~video
of an anchorman or journalist commenting on the case.
We note, however, that many more ranking criteria exist,
which we discuss and classify in the upcoming Section.

\section{Classification and Discussion of Ranking Criteria}
As outlined before, ranking criteria fall in different categories,
which we present in the following.

\paragraph{Visual high-level:}
this category regards the actual contents of media items.
Examples are the detection of logos, the recognition of faces, or, on a more abstract level,
the detection of camera shots~\cite{Crowdsourcing2011}.

\paragraph{Visual low-level:}
this category regards metadata about the raw binary media items.
Examples are file size, pixel resolution, video duration, geolocation,
date and time information, etc.
It is to be noted that for privacy reasons some social networks
remove such potentially identifying information,
this holds especially true for GPS coordinates.

\paragraph{Textual:}
this category regards the microposts that accompany media items.
Typically, microposts provide a textual description of the media item(s) in question.
Using named entity extraction and disambiguation tools,
this textual content can be linked to concepts in the LOD cloud~\cite{Facebook2011}.

\paragraph{Social:}
this category regards social networking effects such as shares, mentions,
number of views, expressions of likes and dislikes, user diversity, etc.
We want to highlight that our previous work allows us
to not only examine these effects within one social network (e.g., ReTweets on Twitter),
but in a \emph{network-agnostic} way for a given query allows us
to examine the overall popularity of a media item.

\paragraph{Aesthetic:}

\section{Conclusion and Future Work}

% back to normal size Computer Modern for URLs in bibliography
\renewcommand{\ttdefault}{cmvtt}
\renewcommand\UrlFont\tt

\bibliographystyle{splncs03}
\bibliography{eswc2012-poster}

\end{document}
